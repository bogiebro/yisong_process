{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911613f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T17:56:05.586227Z",
     "start_time": "2021-11-13T17:56:05.096529Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import Predictive, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "import gpytorch.distributions as gdist\n",
    "import gpytorch as gp\n",
    "\n",
    "import pdb\n",
    "from pmextract import extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b19cc73c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T01:31:04.659415Z",
     "start_time": "2021-11-13T01:31:04.650942Z"
    }
   },
   "outputs": [],
   "source": [
    "G = 5 # max number of functions\n",
    "A = 7 # max number of arguments per function\n",
    "func_alpha = 1.0 # concentration parameter for function DP\n",
    "markov_alpha = 1.0 # concentration parameter for how old your args should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daaba5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T01:31:04.668860Z",
     "start_time": "2021-11-13T01:31:04.660524Z"
    }
   },
   "outputs": [],
   "source": [
    "data = torch.ones(3, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac582cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T18:52:49.134694Z",
     "start_time": "2021-11-13T18:52:49.117401Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyGP(gp.models.ExactGP):\n",
    "    def __init__(self):\n",
    "        super().__init__([], [], gp.likelihoods.GaussianLikelihood())\n",
    "        self.kernel_mod = ScaleKernel(RBFKernel())\n",
    "        self.mean_mod = gp.means.ConstantMean()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = self.mean_mod(x)\n",
    "        covar = self.kernel_mod(x)\n",
    "        return gdist.MultivariateNormal(mean, covar)\n",
    "    \n",
    "    def sample_with_posterior(self, x):\n",
    "        sample = self(x).sample()\n",
    "        if self.prediction_strategy:\n",
    "            return self.get_fantasy_model(x, sample), sample\n",
    "        else:\n",
    "            self.set_train_data(x[None, :], sample[None, :], strict=False)\n",
    "            return self, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "006779a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T18:52:51.331308Z",
     "start_time": "2021-11-13T18:52:51.310567Z"
    }
   },
   "outputs": [],
   "source": [
    "mygp = MyGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85105f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T18:52:51.340619Z",
     "start_time": "2021-11-13T18:52:51.332340Z"
    }
   },
   "outputs": [],
   "source": [
    "foo = torch.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26719202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T18:52:51.350970Z",
     "start_time": "2021-11-13T18:52:51.341462Z"
    }
   },
   "outputs": [],
   "source": [
    "gp2, sample = mygp.sample_with_posterior(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65f0dca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T18:54:59.821029Z",
     "start_time": "2021-11-13T18:54:59.801105Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must train on the training inputs!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_643122/3463496515.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_with_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_643122/213770783.py\u001b[0m in \u001b[0;36msample_with_posterior\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_with_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fantasy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpytorch/models/exact_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You must train on the training inputs!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must train on the training inputs!"
     ]
    }
   ],
   "source": [
    "gp2.sample_with_posterior(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2908f20d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T18:21:18.555265Z",
     "start_time": "2021-11-13T18:21:18.541783Z"
    }
   },
   "outputs": [],
   "source": [
    "mygp.prediction_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9348221a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T18:19:49.946434Z",
     "start_time": "2021-11-13T18:19:49.917490Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Fantasy observations can only be added after making predictions with a model so that all test independent caches exist. Call the model on some data first!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_643122/2999799000.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmygp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fantasy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmygp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpytorch/models/exact_gp.py\u001b[0m in \u001b[0;36mget_fantasy_model\u001b[0;34m(self, inputs, targets, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"Fantasy observations can only be added after making predictions with a model so that \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;34m\"all test independent caches exist. Call the model on some data first!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Fantasy observations can only be added after making predictions with a model so that all test independent caches exist. Call the model on some data first!"
     ]
    }
   ],
   "source": [
    "mygp.get_fantasy_model(foo, mygp(foo).sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0066e4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T18:19:10.212863Z",
     "start_time": "2021-11-13T18:19:10.197618Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyGP' object has no attribute 'get_fantasty_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MyGP' object has no attribute 'get_fantasty_model'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_643122/3320087655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mygp.get_fantasty_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     foo, mygp(foo).sample())\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MyGP' object has no attribute 'get_fantasty_model'"
     ]
    }
   ],
   "source": [
    "mygp.get_fantasty_model(\n",
    "    foo, mygp(foo).sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e74477fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T01:31:04.678007Z",
     "start_time": "2021-11-13T01:31:04.669886Z"
    }
   },
   "outputs": [],
   "source": [
    "class GPKernel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.kernel = ScaleKernel(RBFKernel())\n",
    "    def forward(self, input_locs):\n",
    "        return self.kernel(input_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ed1d730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T01:31:04.686844Z",
     "start_time": "2021-11-13T01:31:04.678777Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel = GPKernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2359722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T01:31:04.695480Z",
     "start_time": "2021-11-13T01:31:04.687516Z"
    }
   },
   "outputs": [],
   "source": [
    "def mix_weights(beta):\n",
    "    \"Turn iid Beta samples into the weights of a categorical (Stick Breaking DP)\"\n",
    "    beta1m_cumprod = (1 - beta).cumprod(-1)\n",
    "    return F.pad(beta, (0, 1), value=1) * F.pad(beta1m_cumprod, (1, 0), value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0224688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T16:36:38.988467Z",
     "start_time": "2021-11-13T16:36:38.971388Z"
    }
   },
   "outputs": [],
   "source": [
    "def partition(num_funcs, func_ids, outputs, inputs):\n",
    "    return [(inputs[func_ids == i], outputs[func_ids == i]) for i in range(num_funcs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9feb4f6",
   "metadata": {},
   "source": [
    "TODO: is there a faster way to do this than re-recalculating the cholesky every time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c8532",
   "metadata": {},
   "source": [
    "To generate, you take the cholesky decomp and multiply by a unit normal.\n",
    "Remember: the new mean is mu + k_*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1801b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(T, M):\n",
    "    mu = torch.randn(G)\n",
    "    num_funcs, from_function, arg_times, arg_vars = model(T, M)\n",
    "    generated = [torch.randn(M)]\n",
    "    for t in range(T-1):\n",
    "        built = []\n",
    "        for v in range(M):\n",
    "            n = T*t + v\n",
    "            args = generated[arg_times[n]][arg_vars[n]]\n",
    "            f = from_function[n]\n",
    "            # Reminder: how do we marginalize the gaussian?\n",
    "            built.append(generated[arg_times[n]][arg_vars[n]])\n",
    "        generated.append(torch.tensor(built))\n",
    "        \n",
    "            \n",
    "    for i in range(num_funcs):\n",
    "    pyro.param(\"mu\")[i:i+1].expand()\n",
    "    func_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5348c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe_data(data):\n",
    "    T, M = data.shape # timesteps by variables\n",
    "    num_funcs, from_function, arg_times, arg_vars = model(T, M)\n",
    "    pairs = partition(num_funcs, from_function, data[1:].view(-1), data[arg_times, arg_vars].T)\n",
    "    mu = pyro.param(\"mu\", torch.randn(G))\n",
    "    for i, pair in enumerate(pairs):\n",
    "        gp_in, gp_out = pair\n",
    "        k_xx = gp.add_diag(kernel(gp_in), 0.01)\n",
    "        pyro.sample(f\"data_{i}\", gdist.MultivariateNormal(mu[i:i+1].expand(k_xx.shape[0]), k_xx), obs=gp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99605bdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T16:41:17.219729Z",
     "start_time": "2021-11-13T16:41:17.201900Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(T, M):\n",
    "    N = (T-1) * M # total number of dependent variables\n",
    "    pyro.module(\"kernel\", kernel)\n",
    "    \n",
    "    with pyro.plate(\"func_betas\", G -1):\n",
    "        func_beta = pyro.sample(\"func_beta\", dist.Beta(1, func_alpha))\n",
    "    with pyro.plate(\"function\", N):\n",
    "        from_function = pyro.sample(\"from_function\", dist.Categorical(mix_weights(func_beta)))\n",
    "        num_funcs = from_function.max() + 1\n",
    "    with pyro.plate(\"arg_betas\", T - 2):\n",
    "        arg_beta = pyro.sample(\"arg_beta\", dist.Beta(1, markov_alpha))\n",
    "    with pyro.plate(\"func_arg_dists\", num_funcs):\n",
    "        func_arg_params = pyro.sample(\"func_arg_weights\", dist.Dirichlet(torch.ones(M)))\n",
    "    time_weights = torch.stack([F.pad(mix_weights(arg_beta[:i]), (0, T - i - 1)) for i in range(T-1)])\n",
    "    with pyro.plate(\"arguments\", N) as varindex:\n",
    "        t = varindex.div(M, rounding_mode='trunc')\n",
    "        with pyro.plate(\"nth_arg\", A):\n",
    "            arg_times = pyro.sample(\"arg_times\", dist.Categorical(time_weights[t]))\n",
    "            arg_vars = pyro.sample(\"arg_vars\", dist.Categorical(func_arg_params[from_function]))\n",
    "    return num_funcs, from_function, arg_times, arg_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "003e574f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T16:41:21.655505Z",
     "start_time": "2021-11-13T16:41:21.636738Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.local/lib/python3.9/site-packages/pyro/primitives.py:138: RuntimeWarning: trying to observe a value outside of inference at data_0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266c070",
   "metadata": {},
   "source": [
    "TODO: pick up from here. Debug this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a928b4",
   "metadata": {},
   "source": [
    "Shouldn't there be 18 variables? Why are there 23?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "875e82e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T01:42:47.223535Z",
     "start_time": "2021-11-13T01:42:47.206538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 18])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ae08290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T01:42:53.531939Z",
     "start_time": "2021-11-13T01:42:53.515042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46b6240c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T01:34:25.003736Z",
     "start_time": "2021-11-13T01:34:18.933364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_641901/2010763094.py\u001b[0m(24)\u001b[0;36mmodel\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     20 \u001b[0;31m            \u001b[0marg_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arg_vars\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_arg_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfrom_function\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m        \u001b[0mgp_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mgp_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgp_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m            \u001b[0mk_xx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgp_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 24 \u001b[0;31m            \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_xx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_xx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgp_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> extract()\n",
      "*** RuntimeError: Copied <module>'s variables to <module>\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68f54d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T01:32:47.514807Z",
     "start_time": "2021-11-13T01:31:41.083299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_641901/947917112.py\u001b[0m(4)\u001b[0;36mpartition\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      2 \u001b[0;31m    \u001b[0;31m# gp_out is a list (size n-funcs) of vectors (size 'examples')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m    \u001b[0;31m# gp_in is a list (size n-funcs) of (examples x n-args) matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 4 \u001b[0;31m    \u001b[0mgp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_ids\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0mgp_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_ids\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mgp_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> func_ids.dtype\n",
      "torch.int64\n",
      "ipdb> type(inputs)\n",
      "<class 'torch.Tensor'>\n",
      "ipdb> inputs[func_ids == i]\n",
      "*** NameError: name 'i' is not defined\n",
      "ipdb> inputs[func_ids == 2]\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.]])\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "407d3e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T23:51:25.158359Z",
     "start_time": "2021-11-12T23:51:25.140563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 27])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[arg_times, arg_vars].shape # which argument x which variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e266dd53",
   "metadata": {},
   "source": [
    "## GP Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4a46c",
   "metadata": {},
   "source": [
    " Start with vanilla GPs. Eventually add fancy stuff like Kroncker structure or SKIP or variational versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef6265",
   "metadata": {},
   "source": [
    "Do we do this variationally, or exactly? We could do it exactly. Finding the log determinant of the covariance matrix will be the part that could take a long time. We could try both. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a9589",
   "metadata": {},
   "source": [
    "To do it exactly, just make the covariance matrix, pass it to gpytorch MultivariateNormal, and you're good to go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45d663",
   "metadata": {},
   "source": [
    "## Other Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf48eab",
   "metadata": {},
   "source": [
    "Idea: Bayesian programming learning in general gets you bounds on the causal effect size at the same time as it produces plausable programs. Because we know the true program is in the posterior somewhere, so if we just sample effects from the posterior at the same time as we sample parameters, we get a bound. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f298f6",
   "metadata": {},
   "source": [
    "Specifically, if we want to know a bound on causal effect size, we can check the differences between observations of $B_t$ in the original and observations of $B_t$ under intervention. That is, to check the causal effect in a given model, sample $\\frac{1}{N}\\sum_{i=1}^N B_t - B_t'$ from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7043ea",
   "metadata": {},
   "source": [
    "What are the interventions here? With binary variables, that's easy. Just set or not set the variable of a variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad1428b",
   "metadata": {},
   "source": [
    "Alternately: there's also the perspective that causal effect MEANS that there's a directed path between the variables. We could just record, for each model sampled, whether such a path exists. This will tell you the posterior probability that A causes B. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
